{
    "name": "appmixer.ai.openai",
    "version": "1.1.2",
    "changelog": {
        "1.0.0": [
            "First version."
        ],
        "1.0.1": [
            "Fixed missing prompt in SendPrompt output variables. Other, small internal improvements."
        ],
        "1.0.2": [
            "TransformTextToJSON: improved error handling for invalid JSON schema input."
        ],
        "1.0.3": [
            "Fixed an error `JSON schema is invalid` that occurred when the AiAgent used a tool with an empty parameters object."
        ],
        "1.1.0": [
            "Add mcp output port for connecting MCP servers.",
            "Memory data store can be selected to store agent memory and summary.",
            "New connector configuration: AI_AGENT_MAX_HISTORY_SIZE (default 512000), llmBaseUrl and llmDefaultHeaders to support other OpenAI SDK compatible LLMs.",
            "Report usage and timing information in the output.",
            "Better performance, assistant API exchanged for chat completion.",
            "Support for streaming responses with built-in chat utility.",
            "Partial agent progress reported via streams too (for built-in chat utility)."
        ],
        "1.1.1": [
            "Fixed a bug which prevented the AI Agent from using MCP server tools."
        ],
        "1.1.2": [
            "Fixed OpenAI API error \"tool_call_ids did not have response messages\" by ensuring all tool call IDs receive responses, even when tools timeout or fail. Added comprehensive error handling for malformed JSON arguments and improved polling logic to guarantee complete tool call coverage. Enhanced logging and reliability for AI conversations when tools experience issues."
        ]
    }
}
